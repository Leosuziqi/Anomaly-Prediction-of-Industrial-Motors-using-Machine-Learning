{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRSY65B1NuV9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('motor-current-81336.csv',index_col='Date',parse_dates=True)\n",
        "df.index.freq='MS'\n",
        "\n",
        "df.plot(figsize=(12,6))\n",
        "     "
      ],
      "metadata": {
        "id": "mjVTudHpds3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "results = seasonal_decompose(df['Production'])\n",
        "results.plot()"
      ],
      "metadata": {
        "id": "SxCxbDakduYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = df.iloc[:len(df)*3/4]\n",
        "test = df.iloc[len(df)*3/4:]"
      ],
      "metadata": {
        "id": "WTrAYZCIings"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "scaler.fit(train)\n",
        "scaled_train = scaler.transform(train)\n",
        "scaled_test = scaler.transform(test)\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "4MAr6BDpdl2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svl-EvjDNur4"
      },
      "source": [
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "# define generator\n",
        "n_input = 3\n",
        "n_features = 1\n",
        "generator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size=1)\n",
        "\n",
        "X,y = generator[0]\n",
        "print(f'Given the Array: \\n{X.flatten()}')\n",
        "print(f'Predict this y: \\n {y}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trained on 12 hours' data(500 sample)\n",
        "n_input = 500\n",
        "generator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size=1)"
      ],
      "metadata": {
        "id": "aP-DooFNjB2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', input_shape=(n_input, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(generator,epochs=50)"
      ],
      "metadata": {
        "id": "O-kHu2BUjB4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_per_epoch = model.history.history['loss']\n",
        "plt.plot(range(len(loss_per_epoch)),loss_per_epoch)"
      ],
      "metadata": {
        "id": "0G3gY_98jWGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_train_batch = last_train_batch.reshape((1, n_input, n_features))\n",
        "\n",
        "model.predict(last_train_batch)"
      ],
      "metadata": {
        "id": "LQhyoSMmjWKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = []\n",
        "\n",
        "first_eval_batch = scaled_train[-n_input:]\n",
        "current_batch = first_eval_batch.reshape((1, n_input, n_features))\n",
        "\n",
        "for i in range(len(test)):\n",
        "    \n",
        "    # get the prediction value for the first batch\n",
        "    current_pred = model.predict(current_batch)[0]\n",
        "    \n",
        "    # append the prediction into the array\n",
        "    test_predictions.append(current_pred) \n",
        "    \n",
        "    # use the prediction to update the batch and remove the first value\n",
        "    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)"
      ],
      "metadata": {
        "id": "vM7lrq4ujWM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_predictions = scaler.inverse_transform(test_predictions)\n",
        "\n",
        "test['Predictions'] = true_predictions\n",
        "     \n",
        "test.plot(figsize=(14,5))"
      ],
      "metadata": {
        "id": "J76fQneBjgor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "rmse=sqrt(mean_squared_error(test['Production'],test['Predictions']))\n",
        "print(rmse)"
      ],
      "metadata": {
        "id": "8pAnF49HjkEM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
